{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "\n",
        "import torch.utils.data\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using MPS\n"
          ]
        }
      ],
      "source": [
        "# Device selection\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Using GPU\")\n",
        "    device = torch.device(\"cuda\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    print(\"Using MPS\")\n",
        "    device = torch.device(\"mps\")\n",
        "else:\n",
        "    print(\"Using CPU\")\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "kwargs = {'num_workers': 1}\n",
        "if torch.cuda.is_available():\n",
        "    kwargs['pin_memory'] = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "\n",
        "batch_size = 64\n",
        "latent_size = 32\n",
        "init_channels = 8\n",
        "class_size = 10  # Number of classes in MNIST (0-9)\n",
        "epochs = 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data loaders\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(\n",
        "        'data', train=True, download=True,\n",
        "        transform=transforms.ToTensor()),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(\n",
        "        'data', train=False, transform=transforms.ToTensor()),\n",
        "    batch_size=batch_size, shuffle=False, **kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper function for one-hot encoding\n",
        "def one_hot(labels, class_size):\n",
        "    targets = torch.zeros(labels.size(0), class_size)\n",
        "    for i, label in enumerate(labels):\n",
        "        targets[i, label] = 1\n",
        "    return targets.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CVAE(nn.Module):\n",
        "    def __init__(self, image_channels, init_channels, latent_size, class_size):\n",
        "        super(CVAE, self).__init__()\n",
        "        self.image_channels = image_channels\n",
        "        self.latent_size = latent_size\n",
        "        self.class_size = class_size\n",
        "        self.init_channels = init_channels\n",
        "        \n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(image_channels, init_channels, kernel_size=3, stride=2, padding=1),     # (1, 28, 28) -> (8, 14, 14)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(init_channels, init_channels*2, kernel_size=3, stride=2, padding=1),    # (8, 14, 14) -> (16, 7, 7)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(init_channels*2, init_channels*4, kernel_size=3, stride=2, padding=1),  # (16, 7, 7) -> (32, 4, 4)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(init_channels*4, 64, kernel_size=3, stride=1, padding=0),               # (32, 4, 4) -> (64, 2, 2)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=2, stride=1, padding=0),                          # (64, 2, 2) -> (64, 1, 1)\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        # FC layers to get mu and logvar\n",
        "        self.fc1 = nn.Linear(64 + self.class_size, 128)\n",
        "        self.fc_mu = nn.Linear(128, latent_size)\n",
        "        self.fc_logvar = nn.Linear(128, latent_size)\n",
        "        self.fc2 = nn.Linear(latent_size + self.class_size, 64)\n",
        "        \n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(64, 64, kernel_size=2, stride=1, padding=0),  # (64, 1, 1) -> (64, 2, 2)\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, init_channels*4, kernel_size=3, stride=1, padding=0),  # (64, 2, 2) -> (32, 4, 4)\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(init_channels*4, init_channels*2, kernel_size=3, stride=2, padding=1),  # (32, 4, 4) -> (16, 7, 7)\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(init_channels*2, init_channels, kernel_size=3, stride=2, padding=1, output_padding=1),  # (16, 7, 7) -> (8, 14, 14)\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(init_channels, image_channels, kernel_size=4, stride=2, padding=1)  # (8, 14, 14) -> (1, 28, 28)\n",
        "        )\n",
        "    \n",
        "    def encode(self, x, c):\n",
        "        h = self.encoder(x)\n",
        "        h = h.view(h.size(0), -1)\n",
        "        inputs = torch.cat([h, c], 1)\n",
        "        h_fc = F.relu(self.fc1(inputs))\n",
        "        mu = self.fc_mu(h_fc)\n",
        "        logvar = self.fc_logvar(h_fc)\n",
        "        return mu, logvar\n",
        "    \n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        sample = mu + eps * std\n",
        "        return sample\n",
        "    \n",
        "    def decode(self, z, c):\n",
        "        inputs = torch.cat([z, c], 1)\n",
        "        h = F.relu(self.fc2(inputs))\n",
        "        h = h.view(-1, 64, 1, 1)\n",
        "        return torch.sigmoid(self.decoder(h))\n",
        "\n",
        "    def forward(self, x, c):\n",
        "        mu, logvar = self.encode(x, c)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        recon_x = self.decode(z, c)\n",
        "        return recon_x, mu, logvar\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    # Reconstruction + KL divergence losses summed over all elements and batch\n",
        "    BCE = F.binary_cross_entropy(recon_x.view(-1, 784), x.view(-1, 784), reduction='sum')\n",
        "    # -0.5 * torch.sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + KLD\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train and Test functions\n",
        "def train(model, optimizer, epoch, losses):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
        "        data, labels = data.to(device), labels.to(device)\n",
        "        \n",
        "        labels_onehot = one_hot(labels, class_size)\n",
        "        recon_batch, mu, logvar = model(data, labels_onehot)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_function(recon_batch, data, mu, logvar)\n",
        "        loss.backward()\n",
        "        train_loss += loss.detach().cpu().numpy()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if batch_idx % 20 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader),\n",
        "                loss.item() / len(data)))\n",
        "    \n",
        "    losses.append(train_loss / len(train_loader.dataset))\n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
        "          epoch, train_loss / len(train_loader.dataset)))\n",
        "\n",
        "def test(model, epoch, losses):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (data, labels) in enumerate(test_loader):\n",
        "            data, labels = data.to(device), labels.to(device)\n",
        "            \n",
        "            labels_onehot = one_hot(labels, class_size)\n",
        "            recon_batch, mu, logvar = model(data, labels_onehot)\n",
        "            test_loss += loss_function(recon_batch, data, mu, logvar).detach().cpu().numpy()\n",
        "            \n",
        "            if i == 0:\n",
        "                n = min(data.size(0), 5)\n",
        "                comparison = torch.cat([data[:n],\n",
        "                                      recon_batch.view(-1, 1, 28, 28)[:n]])\n",
        "                save_image(comparison.cpu(),\n",
        "                         'cvae_reconstruction_' + str(f\"{epoch:02}\") + '.png', nrow=n)\n",
        "\n",
        "    losses.append(test_loss / len(test_loader.dataset))\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('====> Test set loss: {:.4f}'.format(test_loss))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting CVAE training...\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 614.868591\n",
            "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 584.211975\n",
            "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 398.126648\n",
            "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 285.060455\n",
            "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 240.374435\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 225.165527\n",
            "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 214.577240\n",
            "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 210.577774\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 198.468994\n",
            "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 198.501511\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 194.581650\n",
            "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 196.298767\n",
            "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 205.743881\n",
            "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 196.539368\n",
            "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 193.056625\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 202.289093\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 191.911880\n",
            "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 185.104080\n",
            "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 188.797684\n",
            "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 190.575134\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 196.025436\n",
            "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 195.514053\n",
            "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 189.757080\n",
            "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 192.692291\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 192.501892\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 187.549789\n",
            "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 181.646271\n",
            "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 186.082260\n",
            "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 177.725403\n",
            "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 172.037491\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 174.954773\n",
            "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 179.732819\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 180.315125\n",
            "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 179.332977\n",
            "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 164.060028\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 175.523529\n",
            "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 174.075424\n",
            "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 161.209854\n",
            "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 171.008499\n",
            "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 165.583099\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 165.178299\n",
            "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 172.318146\n",
            "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 171.260193\n",
            "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 159.842850\n",
            "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 155.666672\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 155.296234\n",
            "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 165.757446\n",
            "====> Epoch: 1 Average loss: 205.1923\n",
            "====> Test set loss: 156.9646\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 156.235062\n",
            "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 144.809555\n",
            "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 161.790024\n",
            "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 148.360382\n",
            "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 158.565063\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 157.699677\n",
            "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 159.858719\n",
            "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 156.833572\n",
            "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 151.667358\n",
            "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 147.213898\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 152.015778\n",
            "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 151.408203\n",
            "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 148.781845\n",
            "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 155.099030\n",
            "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 156.534790\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 146.766525\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 148.248993\n",
            "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 139.474899\n",
            "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 150.332504\n",
            "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 146.987167\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 141.680786\n",
            "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 143.700531\n",
            "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 147.198120\n",
            "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 157.446594\n",
            "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 146.154358\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 142.565353\n",
            "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 142.104294\n",
            "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 134.622330\n",
            "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 142.177185\n",
            "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 141.765564\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 139.140152\n",
            "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 142.294189\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 141.326233\n",
            "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 144.557068\n",
            "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 134.791046\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 131.435318\n",
            "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 131.462997\n",
            "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 131.384277\n",
            "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 137.074463\n",
            "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 129.146393\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 133.379074\n",
            "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 134.771896\n",
            "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 144.841446\n",
            "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 129.684296\n",
            "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 130.446198\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 130.083191\n",
            "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 138.257126\n",
            "====> Epoch: 2 Average loss: 144.2118\n",
            "====> Test set loss: 136.6774\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 142.452759\n",
            "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 144.105057\n",
            "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 139.332962\n",
            "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 133.606079\n",
            "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 135.647720\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 141.113235\n",
            "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 134.649521\n",
            "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 125.998352\n",
            "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 137.592453\n",
            "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 136.317123\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 131.357452\n",
            "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 130.193192\n",
            "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 136.901596\n",
            "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 134.267258\n",
            "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 132.777008\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 124.741226\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 130.895355\n",
            "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 131.957230\n",
            "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 137.081757\n",
            "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 126.583054\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 135.085602\n",
            "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 131.465439\n",
            "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 134.450638\n",
            "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 134.435715\n",
            "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 135.674637\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 128.646698\n",
            "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 138.930435\n",
            "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 135.558533\n",
            "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 125.800415\n",
            "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 131.857651\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 132.554810\n",
            "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 124.316452\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 137.851715\n",
            "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 134.098083\n",
            "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 128.328018\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 133.677429\n",
            "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 131.903061\n",
            "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 133.153854\n",
            "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 140.314590\n",
            "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 130.010925\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 135.895721\n",
            "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 132.023102\n",
            "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 134.139557\n",
            "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 121.180878\n",
            "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 135.612122\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 136.946274\n",
            "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 123.310181\n",
            "====> Epoch: 3 Average loss: 133.1028\n",
            "====> Test set loss: 130.1823\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 124.887794\n",
            "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 135.729218\n",
            "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 122.544975\n",
            "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 134.061752\n",
            "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 137.384476\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 134.420929\n",
            "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 137.258377\n",
            "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 137.546570\n",
            "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 129.978882\n",
            "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 130.392365\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 132.205017\n",
            "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 126.005737\n",
            "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 130.452118\n",
            "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 126.617180\n",
            "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 125.116577\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 129.786209\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 123.630074\n",
            "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 124.069351\n",
            "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 128.154083\n",
            "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 129.843536\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 125.239464\n",
            "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 117.671509\n",
            "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 126.731331\n",
            "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 132.166122\n",
            "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 125.694069\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 127.131485\n",
            "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 123.387680\n",
            "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 132.473145\n",
            "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 124.349113\n",
            "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 125.834213\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 125.693260\n",
            "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 132.796356\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 135.253906\n",
            "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 118.493637\n",
            "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 131.598328\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 131.450592\n",
            "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 126.836464\n",
            "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 131.153061\n",
            "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 123.814720\n",
            "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 132.534271\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 127.061623\n",
            "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 115.872452\n",
            "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 127.937813\n",
            "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 123.788773\n",
            "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 122.934547\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 118.990524\n",
            "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 121.656372\n",
            "====> Epoch: 4 Average loss: 127.9652\n",
            "====> Test set loss: 126.0204\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 123.947853\n",
            "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 123.962067\n",
            "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 123.117714\n",
            "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 134.976089\n",
            "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 115.611298\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 131.448212\n",
            "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 131.851242\n",
            "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 132.369675\n",
            "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 128.235413\n",
            "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 126.909599\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 127.407127\n",
            "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 126.824768\n",
            "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 126.099060\n",
            "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 125.609535\n",
            "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 123.308563\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 125.764168\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 122.664062\n",
            "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 129.180328\n",
            "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 130.867157\n",
            "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 123.924500\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 116.394806\n",
            "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 125.457016\n",
            "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 116.113884\n",
            "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 127.817703\n",
            "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 123.035873\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 127.124001\n",
            "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 125.241898\n",
            "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 128.949753\n",
            "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 119.212097\n",
            "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 132.778427\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 120.944038\n",
            "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 120.451363\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 119.958168\n",
            "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 130.572479\n",
            "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 117.037094\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 112.227928\n",
            "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 133.770981\n",
            "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 123.805977\n",
            "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 122.528221\n",
            "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 122.658516\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 121.425301\n",
            "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 118.902733\n",
            "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 133.148010\n",
            "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 120.720596\n",
            "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 126.070839\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 130.926910\n",
            "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 129.252014\n",
            "====> Epoch: 5 Average loss: 125.2710\n",
            "====> Test set loss: 123.8318\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 119.056427\n",
            "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 129.433777\n",
            "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 124.096001\n",
            "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 120.917213\n",
            "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 120.602814\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 117.285187\n",
            "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 123.383270\n",
            "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 124.950874\n",
            "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 118.522202\n",
            "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 117.408401\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 118.107803\n",
            "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 124.919830\n",
            "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 132.022263\n",
            "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 129.028732\n",
            "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 117.369415\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 119.975761\n",
            "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 121.056870\n",
            "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 124.435791\n",
            "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 127.519516\n",
            "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 122.812775\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 122.037270\n",
            "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 121.724792\n",
            "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 124.585365\n",
            "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 123.769928\n",
            "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 122.642982\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 125.913597\n",
            "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 126.770004\n",
            "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 123.970200\n",
            "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 119.849411\n",
            "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 115.667969\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 130.021088\n",
            "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 125.310440\n",
            "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 120.912567\n",
            "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 125.343475\n",
            "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 127.784370\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 121.173965\n",
            "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 117.234146\n",
            "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 124.594101\n",
            "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 121.060310\n",
            "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 123.380745\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 125.986023\n",
            "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 115.927002\n",
            "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 125.331566\n",
            "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 127.720566\n",
            "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 119.338417\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 117.061264\n",
            "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 127.867287\n",
            "====> Epoch: 6 Average loss: 123.4531\n",
            "====> Test set loss: 121.8818\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 125.961441\n",
            "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 120.208160\n",
            "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 111.718475\n",
            "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 118.209373\n",
            "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 126.148895\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 123.059006\n",
            "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 117.680450\n",
            "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 129.231491\n",
            "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 122.631355\n",
            "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 110.499985\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 116.577209\n",
            "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 126.525024\n",
            "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 119.774368\n",
            "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 115.910522\n",
            "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 115.032631\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 122.270531\n",
            "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 125.983505\n",
            "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 121.179474\n",
            "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 120.385483\n",
            "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 115.051529\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 128.026398\n",
            "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 119.998497\n",
            "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 104.709099\n",
            "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 115.849411\n",
            "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 125.735168\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 131.078415\n",
            "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 113.017624\n",
            "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 123.563103\n",
            "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 120.361923\n",
            "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 124.629326\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 123.002327\n",
            "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 121.794991\n",
            "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 115.501472\n",
            "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 120.181267\n",
            "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 130.563187\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 123.274139\n",
            "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 122.347580\n",
            "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 123.946503\n",
            "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 124.099205\n",
            "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 118.334587\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 118.482101\n",
            "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 130.817230\n",
            "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 125.564178\n",
            "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 133.076538\n",
            "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 119.852882\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 131.677322\n",
            "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 117.293335\n",
            "====> Epoch: 7 Average loss: 122.0387\n",
            "====> Test set loss: 120.9647\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 118.496994\n",
            "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 111.620682\n",
            "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 123.012932\n",
            "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 120.328705\n",
            "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 121.768753\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 123.856903\n",
            "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 119.101669\n",
            "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 124.214012\n",
            "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 125.098755\n",
            "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 121.087517\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 118.021370\n",
            "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 109.647026\n",
            "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 122.791344\n",
            "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 120.759163\n",
            "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 117.045006\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 126.040649\n",
            "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 115.286858\n",
            "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 115.763199\n",
            "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 110.766830\n",
            "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 127.512939\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 112.102898\n",
            "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 119.836670\n",
            "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 117.231445\n",
            "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 117.305092\n",
            "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 113.005653\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 121.137970\n",
            "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 119.840919\n",
            "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 133.704453\n",
            "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 119.049896\n",
            "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 110.630493\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 120.014130\n",
            "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 124.345207\n",
            "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 117.007355\n",
            "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 131.458115\n",
            "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 117.663887\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 132.341614\n",
            "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 119.675117\n",
            "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 117.722229\n",
            "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 125.419136\n",
            "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 114.184486\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 119.724976\n",
            "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 120.728325\n",
            "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 123.161453\n",
            "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 122.010048\n",
            "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 124.580917\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 117.506706\n",
            "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 121.111008\n",
            "====> Epoch: 8 Average loss: 120.7991\n",
            "====> Test set loss: 119.2743\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 114.508789\n",
            "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 118.743538\n",
            "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 120.509369\n",
            "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 120.755035\n",
            "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 126.128273\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 115.797272\n",
            "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 117.036751\n",
            "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 119.219360\n",
            "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 120.758942\n",
            "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 110.443649\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 113.576691\n",
            "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 119.326935\n",
            "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 118.376740\n",
            "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 113.569466\n",
            "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 117.122986\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 115.088120\n",
            "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 119.092613\n",
            "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 113.161507\n",
            "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 118.346832\n",
            "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 120.882484\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 123.164581\n",
            "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 115.431953\n",
            "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 115.969009\n",
            "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 111.073311\n",
            "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 124.091927\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 111.363808\n",
            "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 120.023445\n",
            "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 117.914215\n",
            "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 118.048889\n",
            "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 116.087402\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 116.306580\n",
            "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 112.514267\n",
            "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 122.264137\n",
            "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 117.433792\n",
            "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 120.102730\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 116.790108\n",
            "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 125.667534\n",
            "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 108.115875\n",
            "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 127.978760\n",
            "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 116.218536\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 114.334373\n",
            "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 109.152451\n",
            "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 122.085876\n",
            "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 124.885048\n",
            "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 122.097946\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 110.819260\n",
            "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 114.849281\n",
            "====> Epoch: 9 Average loss: 118.9505\n",
            "====> Test set loss: 117.3062\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 118.737587\n",
            "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 116.284164\n",
            "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 131.157028\n",
            "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 132.424591\n",
            "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 120.635414\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 110.777283\n",
            "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 121.567055\n",
            "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 111.397888\n",
            "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 119.859734\n",
            "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 113.588425\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 107.627045\n",
            "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 120.057053\n",
            "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 121.757492\n",
            "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 116.434875\n",
            "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 117.454384\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 113.574348\n",
            "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 110.205589\n",
            "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 112.969955\n",
            "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 121.389412\n",
            "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 116.659058\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 118.152901\n",
            "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 112.476692\n",
            "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 117.775307\n",
            "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 122.666260\n",
            "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 125.199074\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 115.172272\n",
            "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 112.799026\n",
            "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 110.711861\n",
            "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 114.115768\n",
            "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 124.352875\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 119.525879\n",
            "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 116.814232\n",
            "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 113.551476\n",
            "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 118.856216\n",
            "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 119.169281\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 116.345886\n",
            "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 116.888786\n",
            "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 118.048592\n",
            "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 122.481979\n",
            "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 114.926918\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 121.489029\n",
            "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 116.104118\n",
            "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 120.979309\n",
            "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 111.837540\n",
            "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 118.463402\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 110.921463\n",
            "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 118.381035\n",
            "====> Epoch: 10 Average loss: 117.2729\n",
            "====> Test set loss: 115.7241\n",
            "Training completed!\n"
          ]
        }
      ],
      "source": [
        "# Initialize and train the CVAE model\n",
        "model = CVAE(image_channels=1, init_channels=init_channels, latent_size=latent_size, class_size=class_size).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "print(\"Starting CVAE training...\")\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train(model, optimizer, epoch, train_losses)\n",
        "    test(model, epoch, test_losses)\n",
        "    \n",
        "    # Generate samples for each class\n",
        "    with torch.no_grad():\n",
        "        # Create one-hot encoding for all 10 classes\n",
        "        c = torch.eye(10, 10).to(device)  # Identity matrix for one-hot encoding\n",
        "        sample = torch.randn(10, latent_size).to(device)\n",
        "        sample = model.decode(sample, c).cpu()\n",
        "        save_image(sample.view(10, 1, 28, 28), \n",
        "                  str(f\"cvae_sample_{epoch:02}.png\"))\n",
        "\n",
        "print(\"Training completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train losses: [np.float32(205.19226), np.float32(144.21182), np.float32(133.10277), np.float32(127.96524), np.float32(125.27095), np.float32(123.45314), np.float32(122.03868), np.float32(120.79906), np.float32(118.95054), np.float32(117.27289)]\n",
            "Test losses: [np.float32(156.96455), np.float32(136.67743), np.float32(130.18228), np.float32(126.020424), np.float32(123.831825), np.float32(121.881836), np.float32(120.9647), np.float32(119.274284), np.float32(117.306175), np.float32(115.7241)]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualize the training and test losses\n",
        "print(\"Train losses:\", train_losses)\n",
        "print(\"Test losses:\", test_losses)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_losses, label='Train Loss', marker='o')\n",
        "plt.plot(test_losses, label='Test Loss', marker='s')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('CVAE Training and Test Losses')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved as 'cvae_model_mnist.pth'\n"
          ]
        }
      ],
      "source": [
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'cvae_model_mnist.pth')\n",
        "print(\"Model saved as 'cvae_model_mnist.pth'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the model (skip training for future use)\n",
        "# model = CVAE(image_channels=1, init_channels=init_channels, latent_size=latent_size, class_size=class_size).to(device)\n",
        "# model.load_state_dict(torch.load('cvae_model_mnist.pth'))\n",
        "# print(\"Model loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating conditional samples...\n",
            "Generated 10 samples of digit 3\n",
            "Generated 10 samples of digit 7\n",
            "Generated 8 samples for each digit (0-9)\n"
          ]
        }
      ],
      "source": [
        "# Conditional generation functions\n",
        "\n",
        "def generate_digit(model, digit, num_samples=10):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        c = torch.zeros(num_samples, class_size).to(device)\n",
        "        c[:, digit] = 1 \n",
        "        z = torch.randn(num_samples, latent_size).to(device)\n",
        "        \n",
        "        sample = model.decode(z, c).cpu())\n",
        "        save_image(sample.view(num_samples, 1, 28, 28), \n",
        "                  f\"cvae_generated_digit_{digit}.png\", nrow=5)\n",
        "        print(f\"Generated {num_samples} samples of digit {digit}\")\n",
        "\n",
        "def generate_all_digits(model, num_samples_per_digit=8):\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        all_samples = []\n",
        "        \n",
        "        for digit in range(10):\n",
        "            c = torch.zeros(num_samples_per_digit, class_size).to(device)\n",
        "            c[:, digit] = 1\n",
        "            z = torch.randn(num_samples_per_digit, latent_size).to(device)\n",
        "            \n",
        "            sample = model.decode(z, c).cpu()\n",
        "            all_samples.append(sample)\n",
        "        \n",
        "        all_samples = torch.cat(all_samples, dim=0)\n",
        "        save_image(all_samples.view(-1, 1, 28, 28), \n",
        "                  \"cvae_all_digits_generated.png\", nrow=num_samples_per_digit)\n",
        "        print(f\"Generated {num_samples_per_digit} samples for each digit (0-9)\")\n",
        "\n",
        "# Generate samples for specific digits\n",
        "print(\"Generating conditional samples...\")\n",
        "generate_digit(model, 3, num_samples=10)  # Generate digit 3\n",
        "generate_digit(model, 7, num_samples=10)  # Generate digit 7\n",
        "generate_all_digits(model, num_samples_per_digit=8)  # Generate all digits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating class interpolations...\n",
            "Generated interpolation from class 0 to class 1\n",
            "Generated interpolation from class 3 to class 8\n",
            "Generated interpolation from class 6 to class 9\n"
          ]
        }
      ],
      "source": [
        "# Latent space interpolation between different classes\n",
        "\n",
        "def interpolate_between_classes(model, class1, class2, num_steps=10):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        c1 = torch.zeros(1, class_size).to(device)\n",
        "        c1[0, class1] = 1\n",
        "        \n",
        "        c2 = torch.zeros(1, class_size).to(device)\n",
        "        c2[0, class2] = 1\n",
        "        \n",
        "        z1 = torch.randn(1, latent_size).to(device)\n",
        "        z2 = torch.randn(1, latent_size).to(device)\n",
        "        \n",
        "        interpolated_samples = []\n",
        "        \n",
        "        for i in range(num_steps):\n",
        "            alpha = i / (num_steps - 1)\n",
        "            z_interp = (1 - alpha) * z1 + alpha * z2\n",
        "            c_interp = (1 - alpha) * c1 + alpha * c2\n",
        "            sample = model.decode(z_interp, c_interp).cpu()\n",
        "            interpolated_samples.append(sample)\n",
        "        \n",
        "        interpolated_samples = torch.cat(interpolated_samples, dim=0)\n",
        "        save_image(interpolated_samples.view(-1, 1, 28, 28), \n",
        "                  f\"cvae_interpolation_{class1}_to_{class2}.png\", nrow=num_steps)\n",
        "        print(f\"Generated interpolation from class {class1} to class {class2}\")\n",
        "\n",
        "print(\"Generating class interpolations...\")\n",
        "interpolate_between_classes(model, 0, 1, num_steps=10)  # 0 to 1\n",
        "interpolate_between_classes(model, 3, 8, num_steps=10)  # 3 to 8\n",
        "interpolate_between_classes(model, 6, 9, num_steps=10)  # 6 to 9\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
